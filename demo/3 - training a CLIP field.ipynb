{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6aa8354-6fec-4b7b-be0e-432b571fa354",
   "metadata": {},
   "source": [
    "# 3. Training a CLIP-Field\n",
    "\n",
    "In this tutorial, we are going to create a CLIP-Field from our saved data. CLIP-Field is an implicit neural field that maps from 3D XYZ coordinates to higher dimensional representations such as CLIP visual features and Sentence-BERT semantic embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fa1a0d1-36a5-4974-8037-03521abbb4ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "678eca98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import pprint\n",
    "import random\n",
    "from typing import Dict, Union\n",
    "\n",
    "import hydra\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "import tqdm\n",
    "from omegaconf import OmegaConf\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "import wandb\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "522b1c6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "from dataloaders import (\n",
    "    R3DSemanticDataset,\n",
    "    DeticDenseLabelledDataset,\n",
    "    ClassificationExtractor,\n",
    ")\n",
    "from misc import ImplicitDataparallel\n",
    "from grid_hash_model import GridCLIPModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd413f6",
   "metadata": {},
   "source": [
    "## Load the data and create a model\n",
    "\n",
    "Now, we will set up the constants and create the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2432180d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up the constants\n",
    "\n",
    "SAVE_DIRECTORY = \"../clip_implicit_model\"\n",
    "DEVICE = \"cuda\"\n",
    "IMAGE_TO_LABEL_CLIP_LOSS_SCALE = 1.0\n",
    "LABEL_TO_IMAGE_LOSS_SCALE = 1.0\n",
    "EXP_DECAY_COEFF = 0.5\n",
    "SAVE_EVERY = 5\n",
    "METRICS = {\n",
    "    \"accuracy\": torchmetrics.Accuracy,\n",
    "}\n",
    "\n",
    "BATCH_SIZE = 11000\n",
    "NUM_WORKERS = 10\n",
    "\n",
    "CLIP_MODEL_NAME = \"ViT-B/32\"\n",
    "SBERT_MODEL_NAME = \"all-mpnet-base-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6f5fb4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the data and create the dataloader created in the previous tutorial notebook\n",
    "\n",
    "training_data = torch.load(\"../detic_labeled_dataset.pt\")\n",
    "max_coords, _ = training_data._label_xyz.max(dim=0)\n",
    "min_coords, _ = training_data._label_xyz.min(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8e96bcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up the model\n",
    "\n",
    "label_model = GridCLIPModel(\n",
    "    image_rep_size=training_data[0][\"clip_image_vector\"].shape[-1],\n",
    "    text_rep_size=training_data[0][\"clip_vector\"].shape[-1],\n",
    "    mlp_depth=1,\n",
    "    mlp_width=600,\n",
    "    log2_hashmap_size=20,\n",
    "    num_levels=18,\n",
    "    level_dim=8,\n",
    "    per_level_scale=2,\n",
    "    max_coords=max_coords,\n",
    "    min_coords=min_coords,\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1f6f4d",
   "metadata": {},
   "source": [
    "## Training and evaulation code\n",
    "\n",
    "Now, we will set up the training and the evaluation code. We will train the model to predict the CLIP/SBert features from the 3D coordinates with a contrastive loss. For evaluation, we will measure the zero-shot label accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea5bd590",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def zero_shot_eval(\n",
    "    classifier: ClassificationExtractor, \n",
    "    predicted_label_latents: torch.Tensor, \n",
    "    predicted_image_latents: torch.Tensor, \n",
    "    language_label_index: torch.Tensor, \n",
    "    metric_calculators: Dict[str, Dict[str, torchmetrics.Metric]]\n",
    "):\n",
    "    \"\"\"Evaluate the model on the zero-shot classification task.\"\"\"\n",
    "    class_probs = classifier.calculate_classifications(\n",
    "        model_text_features=predicted_label_latents,\n",
    "        model_image_features=predicted_image_latents,\n",
    "    )\n",
    "    # Now figure out semantic accuracy and loss.\n",
    "    # Semseg mask is necessary for the boundary case where all the points in the batch are \"unlabeled\"\n",
    "    semseg_mask = torch.logical_and(\n",
    "        language_label_index != -1,\n",
    "        language_label_index < classifier.total_label_classes,\n",
    "    ).squeeze(-1)\n",
    "    if not torch.any(semseg_mask):\n",
    "        classification_loss = torch.zeros_like(semseg_mask).mean(dim=-1)\n",
    "    else:\n",
    "        # Figure out the right classes.\n",
    "        masked_class_prob = class_probs[semseg_mask]\n",
    "        masked_labels = language_label_index[semseg_mask].squeeze(-1).long()\n",
    "        classification_loss = F.cross_entropy(\n",
    "            torch.log(masked_class_prob),\n",
    "            masked_labels,\n",
    "        )\n",
    "        if metric_calculators.get(\"semantic\"):\n",
    "            for _, calculators in metric_calculators[\"semantic\"].items():\n",
    "                _ = calculators(masked_class_prob, masked_labels)\n",
    "    return classification_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2aeb16cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    clip_train_loader: DataLoader,\n",
    "    labelling_model: Union[GridCLIPModel, ImplicitDataparallel],\n",
    "    optim: torch.optim.Optimizer,\n",
    "    epoch: int,\n",
    "    classifier: ClassificationExtractor,\n",
    "    device: Union[str, torch.device] = DEVICE,\n",
    "    exp_decay_coeff: float = EXP_DECAY_COEFF,\n",
    "    image_to_label_loss_ratio: float = IMAGE_TO_LABEL_CLIP_LOSS_SCALE,\n",
    "    label_to_image_loss_ratio: float = LABEL_TO_IMAGE_LOSS_SCALE,\n",
    "    disable_tqdm: bool = False,\n",
    "    metric_calculators: Dict[str, Dict[str, torchmetrics.Metric]] = {},\n",
    "):\n",
    "    \"\"\"\n",
    "    Train the model for one epoch.\n",
    "    \"\"\"\n",
    "    total_loss = 0\n",
    "    label_loss = 0\n",
    "    image_loss = 0\n",
    "    classification_loss = 0\n",
    "    total_samples = 0\n",
    "    total_classification_loss = 0\n",
    "    labelling_model.train()\n",
    "    total = len(clip_train_loader)\n",
    "    for clip_data_dict in tqdm.tqdm(\n",
    "        clip_train_loader,\n",
    "        total=total,\n",
    "        disable=disable_tqdm,\n",
    "        desc=f\"Training epoch {epoch}\",\n",
    "    ):\n",
    "        xyzs = clip_data_dict[\"xyz\"].to(device)\n",
    "        clip_labels = clip_data_dict[\"clip_vector\"].to(device)\n",
    "        clip_image_labels = clip_data_dict[\"clip_image_vector\"].to(device)\n",
    "        image_weights = torch.exp(-exp_decay_coeff * clip_data_dict[\"distance\"]).to(\n",
    "            device\n",
    "        )\n",
    "        label_weights = clip_data_dict[\"semantic_weight\"].to(device)\n",
    "        image_label_index: torch.Tensor = (\n",
    "            clip_data_dict[\"img_idx\"].to(device).reshape(-1, 1)\n",
    "        )\n",
    "        language_label_index: torch.Tensor = (\n",
    "            clip_data_dict[\"label\"].to(device).reshape(-1, 1)\n",
    "        )\n",
    "\n",
    "        (predicted_label_latents, predicted_image_latents) = labelling_model(xyzs)\n",
    "        # Calculate the loss from the image to label side.\n",
    "        batch_size = len(image_label_index)\n",
    "        image_label_mask: torch.Tensor = (\n",
    "            image_label_index != image_label_index.t()\n",
    "        ).float() + torch.eye(batch_size, device=device)\n",
    "        language_label_mask: torch.Tensor = (\n",
    "            language_label_index != language_label_index.t()\n",
    "        ).float() + torch.eye(batch_size, device=device)\n",
    "\n",
    "        # For logging purposes, keep track of negative samples per point.\n",
    "        image_label_mask.requires_grad = False\n",
    "        language_label_mask.requires_grad = False\n",
    "        contrastive_loss_labels = labelling_model.compute_loss(\n",
    "            predicted_label_latents,\n",
    "            clip_labels,\n",
    "            label_mask=language_label_mask,\n",
    "            weights=label_weights,\n",
    "        )\n",
    "        contrastive_loss_images = labelling_model.compute_loss(\n",
    "            predicted_image_latents,\n",
    "            clip_image_labels,\n",
    "            label_mask=image_label_mask,\n",
    "            weights=image_weights,\n",
    "        )\n",
    "        del (\n",
    "            image_label_mask,\n",
    "            image_label_index,\n",
    "            language_label_mask,\n",
    "        )\n",
    "\n",
    "        # Mostly for evaluation purposes, calculate the classification loss.\n",
    "        classification_loss = zero_shot_eval(\n",
    "            classifier, predicted_label_latents, predicted_image_latents, language_label_index, metric_calculators\n",
    "        )\n",
    "\n",
    "        contrastive_loss = (\n",
    "            image_to_label_loss_ratio * contrastive_loss_images\n",
    "            + label_to_image_loss_ratio * contrastive_loss_labels\n",
    "        )\n",
    "\n",
    "        optim.zero_grad(set_to_none=True)\n",
    "        contrastive_loss.backward()\n",
    "        optim.step()\n",
    "        # Clip the temperature term for stability\n",
    "        labelling_model.temperature.data = torch.clamp(\n",
    "            labelling_model.temperature.data, max=np.log(100.0)\n",
    "        )\n",
    "        label_loss += contrastive_loss_labels.detach().cpu().item()\n",
    "        image_loss += contrastive_loss_images.detach().cpu().item()\n",
    "        total_classification_loss += classification_loss.detach().cpu().item()\n",
    "        total_loss += contrastive_loss.detach().cpu().item()\n",
    "        total_samples += 1\n",
    "\n",
    "    to_log = {\n",
    "        \"train_avg/contrastive_loss_labels\": label_loss / total_samples,\n",
    "        \"train_avg/contrastive_loss_images\": image_loss / total_samples,\n",
    "        \"train_avg/semseg_loss\": total_classification_loss / total_samples,\n",
    "        \"train_avg/loss_sum\": total_loss / total_samples,\n",
    "        \"train_avg/labelling_temp\": torch.exp(labelling_model.temperature.data.detach())\n",
    "        .cpu()\n",
    "        .item(),\n",
    "    }\n",
    "    for metric_dict in metric_calculators.values():\n",
    "        for metric_name, metric in metric_dict.items():\n",
    "            try:\n",
    "                to_log[f\"train_avg/{metric_name}\"] = (\n",
    "                    metric.compute().detach().cpu().item()\n",
    "                )\n",
    "            except RuntimeError as e:\n",
    "                to_log[f\"train_avg/{metric_name}\"] = 0.0\n",
    "            metric.reset()\n",
    "    #wandb.log(to_log)\n",
    "    logging.debug(pprint.pformat(to_log, indent=4, width=1))\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a84d1638",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save(\n",
    "    labelling_model: Union[ImplicitDataparallel, GridCLIPModel],\n",
    "    optim: torch.optim.Optimizer,\n",
    "    epoch: int,\n",
    "    save_directory: str = SAVE_DIRECTORY,\n",
    "    saving_dataparallel: bool = False,\n",
    "):\n",
    "    if saving_dataparallel:\n",
    "        to_save = labelling_model.module\n",
    "    else:\n",
    "        to_save = labelling_model\n",
    "    state_dict = {\n",
    "        \"model\": to_save.state_dict(),\n",
    "        \"optim\": optim.state_dict(),\n",
    "        \"epoch\": epoch,\n",
    "    }\n",
    "    torch.save(\n",
    "        state_dict,\n",
    "        f\"{save_directory}/implicit_scene_label_model_latest.pt\",\n",
    "    )\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290e034a",
   "metadata": {},
   "source": [
    "## Set up the auxilary classes\n",
    "\n",
    "Like zero-shot classifier, dataloader, evaluators, optimizer, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5492e990",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 338M/338M [00:04<00:00, 72.9MiB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de0b05fce74544a7ba116a79047eba9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)a8e1d/.gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bde4278a0ff644a9b718eae8f90655cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5455d4562e244e3daefe87af70a7c25d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)b20bca8e1d/README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a55c42632494b218acebee1b885e278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)0bca8e1d/config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63bc15e5d13649ad9f41db404bdc21f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23fe6d4256ca4454bd605cb8b742aad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)e1d/data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a99ffd22b9b4402bfc0f3809815dba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c18ad92d2b04ab19c17ec5e71b8cbb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb17ca43d11b450285bf8abcac3ba3a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1e1976601834ed9a0b853cc93f4c861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)a8e1d/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84efc53ad33546cea9142dc941098b82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6afa8642ed6547ae8ed4bc7d28648c33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)8e1d/train_script.py:   0%|          | 0.00/13.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26fdd5ee71b04001a0c930a2762de827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)b20bca8e1d/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33307ab126f4436f8ec157ee0eae9319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)bca8e1d/modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_classifier = ClassificationExtractor(\n",
    "    clip_model_name=CLIP_MODEL_NAME,\n",
    "    sentence_model_name=SBERT_MODEL_NAME,\n",
    "    class_names=training_data._all_classes,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "541af79d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up our metrics on this dataset.\n",
    "train_metric_calculators = {}\n",
    "train_class_count = {\"semantic\": train_classifier.total_label_classes}\n",
    "average_style = [\"micro\", \"macro\", \"weighted\"]\n",
    "for classes, counts in train_class_count.items():\n",
    "    train_metric_calculators[classes] = {}\n",
    "    for metric_name, metric_cls in METRICS.items():\n",
    "        for avg in average_style:\n",
    "            if \"accuracy\" in metric_name:\n",
    "                new_metric = metric_cls(\n",
    "                    task = \"multiclass\", num_classes=counts, average=avg\n",
    "                ).to(DEVICE)\n",
    "                train_metric_calculators[classes][\n",
    "                    f\"{classes}_{metric_name}_{avg}\"\n",
    "                ] = new_metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79729e00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# No dataparallel for now\n",
    "batch_multiplier = 1\n",
    "\n",
    "clip_train_loader = DataLoader(\n",
    "    training_data,\n",
    "    batch_size=batch_multiplier * BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    ")\n",
    "logging.debug(f\"Total train dataset sizes: {len(training_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa1089ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up optimizer\n",
    "\n",
    "optim = torch.optim.Adam(\n",
    "    label_model.parameters(),\n",
    "    lr=1e-4,\n",
    "    betas=(0.9, 0.999),\n",
    "    weight_decay=0.003,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318b73a4",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "Now we run our training loop and save the model occassionally. We ran this for 5 epochs just to validate everything is working properly, but to train a full model you should train it for longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac06a5fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Thread HandlerThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/micromamba/envs/cf/lib/python3.9/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n",
      "    self._run()\n",
      "  File \"/micromamba/envs/cf/lib/python3.9/site-packages/wandb/sdk/internal/internal_util.py\", line 100, in _run\n",
      "    self._process(record)\n",
      "  File \"/micromamba/envs/cf/lib/python3.9/site-packages/wandb/sdk/internal/internal.py\", line 280, in _process\n",
      "    self._hm.handle(record)\n",
      "  File \"/micromamba/envs/cf/lib/python3.9/site-packages/wandb/sdk/internal/handler.py\", line 136, in handle\n",
      "    handler(record)\n",
      "  File \"/micromamba/envs/cf/lib/python3.9/site-packages/wandb/sdk/internal/handler.py\", line 146, in handle_request\n",
      "    handler(record)\n",
      "  File \"/micromamba/envs/cf/lib/python3.9/site-packages/wandb/sdk/internal/handler.py\", line 695, in handle_request_run_start\n",
      "    self._system_monitor.probe(publish=True)\n",
      "  File \"/micromamba/envs/cf/lib/python3.9/site-packages/wandb/sdk/internal/system/system_monitor.py\", line 186, in probe\n",
      "    self.system_info.publish(system_info)\n",
      "  File \"/micromamba/envs/cf/lib/python3.9/site-packages/wandb/sdk/internal/system/system_info.py\", line 252, in publish\n",
      "    self._save_patches()\n",
      "  File \"/micromamba/envs/cf/lib/python3.9/site-packages/wandb/sdk/internal/system/system_info.py\", line 134, in _save_patches\n",
      "    if self.git.dirty:\n",
      "  File \"/micromamba/envs/cf/lib/python3.9/site-packages/wandb/sdk/lib/git.py\", line 76, in dirty\n",
      "    return self.repo.is_dirty()\n",
      "  File \"/micromamba/envs/cf/lib/python3.9/site-packages/git/repo/base.py\", line 819, in is_dirty\n",
      "    if osp.isfile(self.index.path) and len(self.git.diff(\"--cached\", *default_args)):\n",
      "  File \"/micromamba/envs/cf/lib/python3.9/site-packages/git/cmd.py\", line 741, in <lambda>\n",
      "    return lambda *args, **kwargs: self._call_process(name, *args, **kwargs)\n",
      "  File \"/micromamba/envs/cf/lib/python3.9/site-packages/git/cmd.py\", line 1315, in _call_process\n",
      "    return self.execute(call, **exec_kwargs)\n",
      "  File \"/micromamba/envs/cf/lib/python3.9/site-packages/git/cmd.py\", line 1109, in execute\n",
      "    raise GitCommandError(redacted_command, status, stderr_value, stdout_value)\n",
      "git.exc.GitCommandError: Cmd('git') failed due to: exit code(129)\n",
      "  cmdline: git diff --cached --abbrev=40 --full-index --raw\n",
      "  stderr: 'error: unknown option `cached'\n",
      "usage: git diff --no-index [<options>] <path> <path>\n",
      "\n",
      "Diff output format options\n",
      "    -p, --patch           generate patch\n",
      "    -s, --no-patch        suppress diff output\n",
      "    -u                    generate patch\n",
      "    -U, --unified[=<n>]   generate diffs with <n> lines context\n",
      "    -W, --function-context\n",
      "                          generate diffs with <n> lines context\n",
      "    --raw                 generate the diff in raw format\n",
      "    --patch-with-raw      synonym for '-p --raw'\n",
      "    --patch-with-stat     synonym for '-p --stat'\n",
      "    --numstat             machine friendly --stat\n",
      "    --shortstat           output only the last line of --stat\n",
      "    -X, --dirstat[=<param1,param2>...]\n",
      "                          output the distribution of relative amount of changes for each sub-directory\n",
      "    --cumulative          synonym for --dirstat=cumulative\n",
      "    --dirstat-by-file[=<param1,param2>...]\n",
      "                          synonym for --dirstat=files,param1,param2...\n",
      "    --check               warn if changes introduce conflict markers or whitespace errors\n",
      "    --summary             condensed summary such as creations, renames and mode changes\n",
      "    --name-only           show only names of changed files\n",
      "    --name-status         show only names and status of changed files\n",
      "    --stat[=<width>[,<name-width>[,<count>]]]\n",
      "                          generate diffstat\n",
      "    --stat-width <width>  generate diffstat with a given width\n",
      "    --stat-name-width <width>\n",
      "                          generate diffstat with a given name width\n",
      "    --stat-graph-width <width>\n",
      "                          generate diffstat with a given graph width\n",
      "    --stat-count <count>  generate diffstat with limited lines\n",
      "    --compact-summary     generate compact summary in diffstat\n",
      "    --binary              output a binary diff that can be applied\n",
      "    --full-index          show full pre- and post-image object names on the \"index\" lines\n",
      "    --color[=<when>]      show colored diff\n",
      "    --ws-error-highlight <kind>\n",
      "                          highlight whitespace errors in the 'context', 'old' or 'new' lines in the diff\n",
      "    -z                    do not munge pathnames and use NULs as output field terminators in --raw or --numstat\n",
      "    --abbrev[=<n>]        use <n> digits to display object names\n",
      "    --src-prefix <prefix>\n",
      "                          show the given source prefix instead of \"a/\"\n",
      "    --dst-prefix <prefix>\n",
      "                          show the given destination prefix instead of \"b/\"\n",
      "    --line-prefix <prefix>\n",
      "                          prepend an additional prefix to every line of output\n",
      "    --no-prefix           do not show any source or destination prefix\n",
      "    --inter-hunk-context <n>\n",
      "                          show context between diff hunks up to the specified number of lines\n",
      "    --output-indicator-new <char>\n",
      "                          specify the character to indicate a new line instead of '+'\n",
      "    --output-indicator-old <char>\n",
      "                          specify the character to indicate an old line instead of '-'\n",
      "    --output-indicator-context <char>\n",
      "                          specify the character to indicate a context instead of ' '\n",
      "\n",
      "Diff rename options\n",
      "    -B, --break-rewrites[=<n>[/<m>]]\n",
      "                          break complete rewrite changes into pairs of delete and create\n",
      "    -M, --find-renames[=<n>]\n",
      "                          detect renames\n",
      "    -D, --irreversible-delete\n",
      "                          omit the preimage for deletes\n",
      "    -C, --find-copies[=<n>]\n",
      "                          detect copies\n",
      "    --find-copies-harder  use unmodified files as source to find copies\n",
      "    --no-renames          disable rename detection\n",
      "    --rename-empty        use empty blobs as rename source\n",
      "    --follow              continue listing the history of a file beyond renames\n",
      "    -l <n>                prevent rename/copy detection if the number of rename/copy targets exceeds given limit\n",
      "\n",
      "Diff algorithm options\n",
      "    --minimal             produce the smallest possible diff\n",
      "    -w, --ignore-all-space\n",
      "                          ignore whitespace when comparing lines\n",
      "    -b, --ignore-space-change\n",
      "                          ignore changes in amount of whitespace\n",
      "    --ignore-space-at-eol\n",
      "                          ignore changes in whitespace at EOL\n",
      "    --ignore-cr-at-eol    ignore carrier-return at the end of line\n",
      "    --ignore-blank-lines  ignore changes whose lines are all blank\n",
      "    -I, --ignore-matching-lines <regex>\n",
      "                          ignore changes whose all lines match <regex>\n",
      "    --indent-heuristic    heuristic to shift diff hunk boundaries for easy reading\n",
      "    --patience            generate diff using the \"patience diff\" algorithm\n",
      "    --histogram           generate diff using the \"histogram diff\" algorithm\n",
      "    --diff-algorithm <algorithm>\n",
      "                          choose a diff algorithm\n",
      "    --anchored <text>     generate diff using the \"anchored diff\" algorithm\n",
      "    --word-diff[=<mode>]  show word diff, using <mode> to delimit changed words\n",
      "    --word-diff-regex <regex>\n",
      "                          use <regex> to decide what a word is\n",
      "    --color-words[=<regex>]\n",
      "                          equivalent to --word-diff=color --word-diff-regex=<regex>\n",
      "    --color-moved[=<mode>]\n",
      "                          moved lines of code are colored differently\n",
      "    --color-moved-ws <mode>\n",
      "                          how white spaces are ignored in --color-moved\n",
      "\n",
      "Other diff options\n",
      "    --relative[=<prefix>]\n",
      "                          when run from subdir, exclude changes outside and show relative paths\n",
      "    -a, --text            treat all files as text\n",
      "    -R                    swap two inputs, reverse the diff\n",
      "    --exit-code           exit with 1 if there were differences, 0 otherwise\n",
      "    --quiet               disable all output of the program\n",
      "    --ext-diff            allow an external diff helper to be executed\n",
      "    --textconv            run external text conversion filters when comparing binary files\n",
      "    --ignore-submodules[=<when>]\n",
      "                          ignore changes to submodules in the diff generation\n",
      "    --submodule[=<format>]\n",
      "                          specify how differences in submodules are shown\n",
      "    --ita-invisible-in-index\n",
      "                          hide 'git add -N' entries from the index\n",
      "    --ita-visible-in-index\n",
      "                          treat 'git add -N' entries as real in the index\n",
      "    -S <string>           look for differences that change the number of occurrences of the specified string\n",
      "    -G <regex>            look for differences that change the number of occurrences of the specified regex\n",
      "    --pickaxe-all         show all changes in the changeset with -S or -G\n",
      "    --pickaxe-regex       treat <string> in -S as extended POSIX regular expression\n",
      "    -O <file>             control the order in which files appear in the output\n",
      "    --rotate-to <path>    show the change in the specified path first\n",
      "    --skip-to <path>      skip the output to the specified path\n",
      "    --find-object <object-id>\n",
      "                          look for differences that change the number of occurrences of the specified object\n",
      "    --diff-filter [(A|C|D|M|R|T|U|X|B)...[*]]\n",
      "                          select files by diff type\n",
      "    --output <file>       Output to a specific file\n",
      "'\n",
      "wandb: ERROR Internal wandb error: file data was not synced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem at: /tmp/ipykernel_91/617730258.py 1 <module>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/micromamba/envs/cf/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 1133, in init\n",
      "    run = wi.init()\n",
      "  File \"/micromamba/envs/cf/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 787, in init\n",
      "    run_start_result = run_start_handle.wait(timeout=30)\n",
      "  File \"/micromamba/envs/cf/lib/python3.9/site-packages/wandb/sdk/lib/mailbox.py\", line 271, in wait\n",
      "    raise MailboxError(\"transport failed\")\n",
      "wandb.errors.MailboxError: transport failed\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Abnormal program exit\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "problem",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMailboxError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/micromamba/envs/cf/lib/python3.9/site-packages/wandb/sdk/wandb_init.py:1133\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m     run \u001b[38;5;241m=\u001b[39m \u001b[43mwi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m     except_exit \u001b[38;5;241m=\u001b[39m wi\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39m_except_exit\n",
      "File \u001b[0;32m/micromamba/envs/cf/lib/python3.9/site-packages/wandb/sdk/wandb_init.py:787\u001b[0m, in \u001b[0;36m_WandbInit.init\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;66;03m# TODO: add progress to let user know we are doing something\u001b[39;00m\n\u001b[0;32m--> 787\u001b[0m run_start_result \u001b[38;5;241m=\u001b[39m \u001b[43mrun_start_handle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_start_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/micromamba/envs/cf/lib/python3.9/site-packages/wandb/sdk/lib/mailbox.py:271\u001b[0m, in \u001b[0;36mMailboxHandle.wait\u001b[0;34m(self, timeout, on_probe, on_progress, release, cancel)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interface\u001b[38;5;241m.\u001b[39m_transport_keepalive_failed():\n\u001b[0;32m--> 271\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MailboxError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransport failed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    273\u001b[0m found, abandoned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slot\u001b[38;5;241m.\u001b[39m_get_and_clear(timeout\u001b[38;5;241m=\u001b[39mwait_timeout)\n",
      "\u001b[0;31mMailboxError\u001b[0m: transport failed",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclipfields\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Set the extra parameters.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m wandb\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mweb_labelled_points \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(training_data)\n",
      "File \u001b[0;32m/micromamba/envs/cf/lib/python3.9/site-packages/wandb/sdk/wandb_init.py:1170\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1168\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m except_exit:\n\u001b[1;32m   1169\u001b[0m             os\u001b[38;5;241m.\u001b[39m_exit(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m-> 1170\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproblem\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merror_seen\u001b[39;00m\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m run\n",
      "\u001b[0;31mException\u001b[0m: problem"
     ]
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"clipfields\",\n",
    ")\n",
    "# Set the extra parameters.\n",
    "wandb.config.web_labelled_points = len(training_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fb3671d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 0: 100%|███████████████████████████████████████| 91/91 [00:09<00:00,  9.92it/s]\n",
      "Training epoch 1: 100%|███████████████████████████████████████| 91/91 [00:09<00:00, 10.06it/s]\n",
      "Training epoch 2: 100%|███████████████████████████████████████| 91/91 [00:08<00:00, 10.24it/s]\n",
      "Training epoch 3: 100%|███████████████████████████████████████| 91/91 [00:08<00:00, 10.19it/s]\n",
      "Training epoch 4: 100%|███████████████████████████████████████| 91/91 [00:08<00:00, 10.24it/s]\n",
      "Training epoch 5: 100%|███████████████████████████████████████| 91/91 [00:09<00:00, 10.08it/s]\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\" # Just to reduce excessive logging from sbert\n",
    "\n",
    "epoch = 0\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "while epoch <= NUM_EPOCHS:\n",
    "    train(\n",
    "        clip_train_loader,\n",
    "        label_model,\n",
    "        optim,\n",
    "        epoch,\n",
    "        train_classifier,\n",
    "        metric_calculators=train_metric_calculators,\n",
    "    )\n",
    "    epoch += 1\n",
    "    if epoch % SAVE_EVERY == 0:\n",
    "        save(label_model, optim, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54ff760-c0eb-4ace-b1e7-fc92a03c62be",
   "metadata": {},
   "source": [
    "This is saved already in `../clip_implicit_model`, so we don't have to save our trained model again. You can see the run data on [Weights and biases](https://wandb.ai/mahi/clipfields/runs/j12j175e). On our next tutorial episode, we will evaluate our model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "db1f79a380f3c855f0bd6a6f1ad2b80d271c32dcf53749ce06204dd6e0a63f81"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
